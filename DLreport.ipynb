{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e662218e-ccd5-44e5-a1ac-9eefacd8e086",
   "metadata": {},
   "source": [
    "**Deep Learnig course - Semester Project**\n",
    "\n",
    "The Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases (IQ-OTH/NCCD) lung cancer dataset was collected in the above-mentioned specialist hospitals over a period of three months in fall 2019. It includes CT scans of patients diagnosed with lung cancer in different stages, as well as healthy subjects. IQ-OTH/NCCD slides were marked by oncologists and radiologists in these two centers. The dataset contains a total of 1190 images representing CT scan slices of 110 cases. These cases were grouped into 2 categories according the presence of tumor or not. Initially, the dataset comprised three distinct categories. For the purposes of this study, these categories were consolidated into two broader groups. This adjustment was made to enhance the interpretability of the results and to ensure a more robust analysis by reducing potential class imbalance and increasing the sample size within each group.\n",
    "\n",
    "\n",
    "**1st part of analysis**\n",
    "At first, the data set was slit into train and test groups and then a Convulation Neural Network was built. The CNN is comprised of 4 layers and then trained with different epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771b345-6040-4b17-a1dc-edcacab15416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import sklearn.metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6ee75-94ba-47c1-9496-2de3c2cd3872",
   "metadata": {},
   "source": [
    " Data Loading & Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d7d9b-ea83-4d55-ad61-9f0bb2d69972",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r'/home/konnie/lungdb'\n",
    "class_folders = ['Tumor', 'Normal']\n",
    "target_size = (224, 224) \n",
    "valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_idx, folder_name in enumerate(class_folders):\n",
    "    class_path = os.path.join(dataset, folder_name)\n",
    "    \n",
    "   \n",
    "    class_images = [\n",
    "        os.path.join(class_path, fname)\n",
    "        for fname in os.listdir(class_path)\n",
    "        if fname.lower().endswith(valid_extensions)\n",
    "    ]\n",
    "  \n",
    "    for img_path in class_images:\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                img_resized = img.resize(target_size)\n",
    "                images.append(np.array(img_resized))\n",
    "                labels.append(class_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "images_array = np.array(images)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "print(f\"Images array shape: {images_array.shape}\")  \n",
    "print(f\"Labels array shape: {labels_array.shape}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12613598-0bdc-4bc4-ac9c-7f2b279a8118",
   "metadata": {},
   "source": [
    "Visualize the two Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd7bc1-afb0-49b1-9900-48ea5771c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Normal case', 'Tumor case']\n",
    "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset,\n",
    "    labels='inferred',\n",
    "    label_mode='int', \n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72caf6f3-9468-441a-9e30-f835371bd2ec",
   "metadata": {},
   "source": [
    "Split Dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd9269-ae1c-48b7-b197-ced69c0eee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    images_array, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"The data type of the images is:\", x_train.dtype)\n",
    "print(\"The shape of the train set:\", x_train.shape)\n",
    "print(\"The shape of the test set:\", x_test.shape)\n",
    "print(\"Number of training observations:\", x_train.shape[0])\n",
    "print(\"Number of testing observations:\", x_test.shape[0])\n",
    "print(\"Train label distribution:\", Counter(y_train))\n",
    "print(\"Test label distribution:\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4a4a6-a8f3-4030-8ddb-a7929f112596",
   "metadata": {},
   "source": [
    "Data Preprocessing - Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a392a-3bf9-4cd7-9416-5e896f360a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Value interval of the train set before the min-max normalization:[{x_train.min()},{x_train.max()}]\")\n",
    "print(f\"Value interval of the test set before the min-max normalization:[{x_test.min()},{x_test.max()}]\")\n",
    "# scale the pixels to the [0,1] range\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "print(f\"Value interval of the train set after the min-max normalization:[{x_train.min()},{x_train.max()}]\")\n",
    "print(f\"Value interval of the test set after the min-max normalization:[{x_test.min()},{x_test.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e6626-d523-4478-8563-0d87165eb6fd",
   "metadata": {},
   "source": [
    "CNN Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48d17e-6368-4504-abb3-c24404a22bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),         \n",
    "                    \n",
    "    layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(2, activation=\"softmax\")  # For 2 classes: Normal and Tumor\n",
    "])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ace595-56cc-427e-b1d7-4d4c4d986174",
   "metadata": {},
   "source": [
    "Data Augmentation using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e58292-3594-4b1e-aa3f-c4f5fcb45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=15,      \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=True,   \n",
    "    zoom_range=0.1,         \n",
    "    fill_mode='nearest',    \n",
    "    validation_split=0.2    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1801b-0951-4d97-be3b-f20d91495f24",
   "metadata": {},
   "source": [
    "Compile the model without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44446edf-c6a9-46a8-af33-bf717c830e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c677ac-b45b-4b93-993e-000cd578cf15",
   "metadata": {},
   "source": [
    "Train and Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ac0f5-6c2d-4b31-ad72-36274036cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and validation flows\n",
    "train_generator = data_augmentation.flow(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = data_augmentation.flow(\n",
    "    x_train, y_train, \n",
    "    batch_size=32,\n",
    "    subset='validation',\n",
    "    shuffle=False  # Don't shuffle validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f88a9-19ed-4a3c-b668-e4bbc681bad4",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93019e1-643a-4731-ae30-a7eceb255f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn1 = cnn_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train) * 0.8 // 32,  # 80% of data is used for training with validation_split=0.2\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(x_train) * 0.2 // 32,  # 20% of data is used for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826a0fa-422d-4da2-8fc3-3f96fdbed461",
   "metadata": {},
   "source": [
    "Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662f2e6-c89d-46da-9333-bd5ecd5b320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_cnn1, \"CNN with 10 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b60c2-7499-438a-baed-377681cfa581",
   "metadata": {},
   "source": [
    "Train the CNN with 30 epochs and plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8317d1-7264-4c30-915b-838eb275fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn2 = cnn_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train) * 0.8 // 32,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(x_train) * 0.2 // 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89012aae-228d-4d5e-96c0-220b1191f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_cnn2, \"Simple CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cc705-77c9-4962-8c15-cd9b0b1a0bea",
   "metadata": {},
   "source": [
    "Train the CNN with 50 epochs and plot the accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464231-127d-4b9f-bc83-ea1e917d20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn3 = cnn_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train) * 0.8 // 64,\n",
    "    epochs= 50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(x_train) * 0.2 // 64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45773ef4-43b2-4fe4-b269-58405775db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_cnn3, \"Simple CNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d5e82-99da-4b89-87bc-278266d1b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_comparison(histories, names=None, figsize=(10, 6)):\n",
    "\n",
    "    if names is None:\n",
    "        names = [f\"Model {i+1}\" for i in range(len(histories))]\n",
    "        \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, orange, green\n",
    "    line_styles = ['-', '--']  # Solid for train, dashed for validation\n",
    "    \n",
    "    for i, history in enumerate(histories):\n",
    "        # Convert to dict if it's a Keras History object\n",
    "        if hasattr(history, 'history'):\n",
    "            history = history.history\n",
    "            \n",
    "        # Plot training accuracy\n",
    "        epochs = range(1, len(history['accuracy']) + 1)\n",
    "        plt.plot(epochs, history['accuracy'], \n",
    "                 color=colors[i], linestyle=line_styles[0],\n",
    "                 marker='o', markersize=4, \n",
    "                 label=f'{names[i]} (train)')\n",
    "        \n",
    "        # Plot validation accuracy\n",
    "        if 'val_accuracy' in history:\n",
    "            plt.plot(epochs, history['val_accuracy'], \n",
    "                     color=colors[i], linestyle=line_styles[1],\n",
    "                     marker='s', markersize=4, \n",
    "                     label=f'{names[i]} (val)')\n",
    "    \n",
    "    plt.title('Model Accuracy Comparison', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    # Set y-axis to start from a reasonable minimum - FIXED THIS LINE\n",
    "    y_vals = []\n",
    "    for h in histories:\n",
    "        if hasattr(h, 'history'):\n",
    "            y_vals.extend(h.history['accuracy'])\n",
    "        else:\n",
    "            y_vals.extend(h['accuracy'])\n",
    "    \n",
    "    y_min = max(0, min(y_vals) - 0.05)  # Leave some margin\n",
    "    plt.ylim(bottom=y_min, top=1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4df901-95c5-49d1-b442-21e27b3ccd91",
   "metadata": {},
   "source": [
    "The model was trained for 10, 30 and 50 epochs, and the results were evaluated using accuracy and loss plots for training and validation data. These key observations were made: \n",
    "\n",
    "**Training Duration:** Increasing epochs from 10 to 50 improved test accuracy from 0.918 to 0.95, with most gains occurring in early epochs.\n",
    "**Performance Stability:** Shorter training (10 epochs) yielded remarkably stable learning curves, while longer training introduced significant    volatility without proportional accuracy gains.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8f251-f38f-4b15-a094-e63d1aae7e58",
   "metadata": {},
   "source": [
    "plots comparing the training runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54cf1ef-2753-4e9c-b8ae-1e3c4d4ef638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title):\n",
    "    \"\"\"Plot the training and validation accuracy/loss\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title(f'{title} - Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title(f'{title} - Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afbee2-50bf-453b-b299-3359a2fe406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    [history_cnn1, history_cnn2, history_cnn3], \n",
    "    names=['First Run', 'Second Run', 'Third Run']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf784f2-2dd4-45e3-9106-4b0b9e993e18",
   "metadata": {},
   "source": [
    "Evaluation of the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0300c-9465-4485-8349-0162dbb16ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance and save metrics\n",
    "def evaluate_model(model, test_generator, save_results=True):\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    # Run evaluation on test/validation set\n",
    "    results = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    # Extract metrics\n",
    "    loss = results[0]\n",
    "    accuracy = results[1]\n",
    "    \n",
    "    # Create dictionary of all metrics\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # Additional metrics if available in the model\n",
    "    metrics_names = model.metrics_names\n",
    "    for i, metric_name in enumerate(metrics_names):\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            metrics[metric_name] = results[i]\n",
    "    \n",
    "    # Print results with nice formatting\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Loss:     {loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Print additional metrics if available\n",
    "    for metric_name, value in metrics.items():\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Save results to file if requested\n",
    "    if save_results:\n",
    "        import datetime\n",
    "        import os\n",
    "        \n",
    "        # Create results directory if it doesn't exist\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "            \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(f'results/model_evaluation_{timestamp}.txt', 'w') as f:\n",
    "            f.write(\"MODEL EVALUATION RESULTS\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Loss: {loss:.6f}\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.6f}\\n\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                if metric_name not in ['loss', 'accuracy']:\n",
    "                    f.write(f\"{metric_name}: {value:.6f}\\n\")\n",
    "                    \n",
    "        print(f\"Results saved to results/model_evaluation_{timestamp}.txt\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model_cnn, validation_generator)\n",
    "\n",
    "# Access individual metrics\n",
    "final_accuracy = metrics['accuracy']\n",
    "final_loss = metrics['loss']\n",
    "\n",
    "print(f\"Final model accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Final model loss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da313bb5-15d4-44e8-bbac-431bd2b8b524",
   "metadata": {},
   "source": [
    "**RESNET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee499c1-9268-4ecd-918b-d06b6cc2287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = resnet_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=resnet_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee5406-e208-42be-a03b-0e924ad9b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e6378-00ce-4cc7-ac0c-d9012bb893ec",
   "metadata": {},
   "source": [
    "**Efficient Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b8560-a09f-4484-ad11-76a643b85148",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet', \n",
    "                           include_top=False, \n",
    "                           input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  \n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)  \n",
    "num_classes = 2  # Change this to match your dataset classes (e.g., 2, 3, etc.)\n",
    "predictions = Dense(1, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model_eff = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942d984-cd4e-4250-bff8-4cd3fa5cf361",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351bebfb-2f35-40bf-9582-991b64069bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfced24-9b16-4059-a39b-b45bec829259",
   "metadata": {},
   "source": [
    "Early stopping & reduce learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9c859-4c22-4254-bd55-cae65f9f984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53ede-8161-47ab-b897-382b1feebd67",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36695055-4e3e-4c8e-aedf-c9093bb0580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "history_eff10 = model_eff.fit(\n",
    "    train_generator,\n",
    "    epochs= 10,\n",
    "    validation_data=validation_generator,\n",
    "    #callbacks = callbacks\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67d87d-2481-44dc-9c6f-1447f1d6366e",
   "metadata": {},
   "source": [
    "Plot the accuracy and loss of EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788fd06-5e2a-4c33-89cd-d67c2e5eed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_eff10, \"Efficient net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28514a8-acce-4fd4-9c24-cc0f474fde6d",
   "metadata": {},
   "source": [
    "Train EfficientNet with 30 epochs and plot the accuracy an dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130f228-31e3-4b05-bc37-b2ed9232bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_eff30 = model_eff.fit(\n",
    "    train_generator,\n",
    "    epochs= 30,\n",
    "    validation_data=validation_generator,\n",
    "    #callbacks = callbacks\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4808b-0727-4631-9c52-bc002b76087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_eff30, \"Efficient net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8e6b1-92e3-4e4d-a10c-4fb3a2e58c52",
   "metadata": {},
   "source": [
    "Evaluate efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d99e35-469c-41c3-9ff2-6605e0fb5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance and save metrics\n",
    "def evaluate_model(model, test_generator, save_results=True):\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    # Run evaluation on test/validation set\n",
    "    results = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    # Extract metrics\n",
    "    loss = results[0]\n",
    "    accuracy = results[1]\n",
    "    \n",
    "    # Create dictionary of all metrics\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # Additional metrics if available in the model\n",
    "    metrics_names = model.metrics_names\n",
    "    for i, metric_name in enumerate(metrics_names):\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            metrics[metric_name] = results[i]\n",
    "    \n",
    "    # Print results with nice formatting\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Loss:     {loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Print additional metrics if available\n",
    "    for metric_name, value in metrics.items():\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Save results to file if requested\n",
    "    if save_results:\n",
    "        import datetime\n",
    "        import os\n",
    "        \n",
    "        # Create results directory if it doesn't exist\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "            \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(f'results/model_evaluation_{timestamp}.txt', 'w') as f:\n",
    "            f.write(\"MODEL EVALUATION RESULTS\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Loss: {loss:.6f}\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.6f}\\n\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                if metric_name not in ['loss', 'accuracy']:\n",
    "                    f.write(f\"{metric_name}: {value:.6f}\\n\")\n",
    "                    \n",
    "        print(f\"Results saved to results/model_evaluation_{timestamp}.txt\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model_eff, validation_generator)\n",
    "\n",
    "# Access individual metrics\n",
    "final_accuracy = metrics['accuracy']\n",
    "final_loss = metrics['loss']\n",
    "\n",
    "print(f\"Final model accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Final model loss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c727a74-8c97-473a-8f07-f2c43d8182bd",
   "metadata": {},
   "source": [
    "**MobileNetV2**\n",
    "\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01842d5-bf1c-47fd-9009-a1b052edc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model_mobnet = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model_mobnet.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1bb67-b6b5-4aee-9467-6169d428b982",
   "metadata": {},
   "source": [
    "Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d8b2f-84e2-4a3e-afa0-8b83834623eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model_mobnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Binary classification output\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model_mobnet = Model(inputs=base_model_mobnet.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b590250-50a7-4099-83b5-c08f932693bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c401c-82b4-4c2a-b1e6-953add185d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_mobnet.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model_mobnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44e2c3-34ea-48f2-85a1-2045c570f0bd",
   "metadata": {},
   "source": [
    "Add early stopping and reduction of learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdaf574-6add-4606-80b5-92b9fb70e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up simple callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db25a95-1975-447a-837d-7debdfb25f6e",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dff328-994a-4b1d-ba8c-5ae4b153ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_mobnet10 = model_mobnet.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09115c-de10-4d24-b7a8-0b79ff580e53",
   "metadata": {},
   "source": [
    "Plot the accuracy and the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371307c3-fb74-48b9-ab3b-4b912ce96f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_mobnet10, \"Mobile Net\")\n",
    "\n",
    "predictions_nn_probs_mobnet10 = model_mobnet.predict(x_test)\n",
    "predictions_nn_mobnet10 = np.argmax(predictions_nn_probs_mobnet10, axis=1)\n",
    "test_accuracy_nn_mobnet10 = sklearn.metrics.accuracy_score(y_test, predictions_nn_mobnet10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36b41b-5825-492e-b700-9553a3412203",
   "metadata": {},
   "source": [
    "Train again with 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e934e-fd6e-4689-98f1-0d98034d5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_mobnet30 = model_mobnet.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebb4a4-10c7-4860-9a50-e640995c5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history_mobnet30, \"Mobile Net\")\n",
    "\n",
    "predictions_nn_probs_mobnet30 = model_mobnet.predict(x_test)\n",
    "predictions_nn_mobnet30 = np.argmax(predictions_nn_probs_mobnet30, axis=1)\n",
    "test_accuracy_nn_mobnet30 = sklearn.metrics.accuracy_score(y_test, predictions_nn_mobnet30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b35c91-0b9e-483f-96b5-858131cfcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance and save metrics\n",
    "def evaluate_model(model, test_generator, save_results=True):\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    # Run evaluation on test/validation set\n",
    "    results = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    # Extract metrics\n",
    "    loss = results[0]\n",
    "    accuracy = results[1]\n",
    "    \n",
    "    # Create dictionary of all metrics\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # Additional metrics if available in the model\n",
    "    metrics_names = model.metrics_names\n",
    "    for i, metric_name in enumerate(metrics_names):\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            metrics[metric_name] = results[i]\n",
    "    \n",
    "    # Print results with nice formatting\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Loss:     {loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Print additional metrics if available\n",
    "    for metric_name, value in metrics.items():\n",
    "        if metric_name not in ['loss', 'accuracy']:\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Save results to file if requested\n",
    "    if save_results:\n",
    "        import datetime\n",
    "        import os\n",
    "        \n",
    "        # Create results directory if it doesn't exist\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "            \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(f'results/model_evaluation_{timestamp}.txt', 'w') as f:\n",
    "            f.write(\"MODEL EVALUATION RESULTS\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Loss: {loss:.6f}\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.6f}\\n\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                if metric_name not in ['loss', 'accuracy']:\n",
    "                    f.write(f\"{metric_name}: {value:.6f}\\n\")\n",
    "                    \n",
    "        print(f\"Results saved to results/model_evaluation_{timestamp}.txt\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model_mobnet, validation_generator)\n",
    "\n",
    "# Access individual metrics\n",
    "final_accuracy = metrics['accuracy']\n",
    "final_loss = metrics['loss']\n",
    "\n",
    "print(f\"Final model accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Final model loss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979424eb-14e2-4086-a148-3855e5dd25be",
   "metadata": {},
   "source": [
    "**Compare the three models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf591a-f871-40ea-a0a9-5263bb105d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_model_comparison(model_histories, model_names, save_plot=True):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    train_line_style = '-'  # solid line\n",
    "    val_line_style = '--'   # dashed line\n",
    "    \n",
    "   \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "  \n",
    "    for i, (history, name) in enumerate(zip(model_histories, model_names)):\n",
    "        epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "       \n",
    "        plt.plot(\n",
    "            epochs, \n",
    "            history.history['accuracy'], \n",
    "            train_line_style,\n",
    "            color=colors[i % len(colors)],\n",
    "            linewidth=2,\n",
    "            label=f'{name} (Train)'\n",
    "        )\n",
    "        \n",
    "     \n",
    "        plt.plot(\n",
    "            epochs, \n",
    "            history.history['val_accuracy'], \n",
    "            val_line_style,\n",
    "            color=colors[i % len(colors)],\n",
    "            linewidth=2,\n",
    "            label=f'{name} (Val)'\n",
    "        )\n",
    "    \n",
    "   \n",
    "    for i, (history, name) in enumerate(zip(model_histories, model_names)):\n",
    "       \n",
    "        plt.scatter(\n",
    "            len(history.history['accuracy']),\n",
    "            history.history['accuracy'][-1],\n",
    "            s=100,\n",
    "            color=colors[i % len(colors)],\n",
    "            zorder=5,\n",
    "            marker='o'\n",
    "        )\n",
    "        \n",
    "      \n",
    "        plt.scatter(\n",
    "            len(history.history['val_accuracy']),\n",
    "            history.history['val_accuracy'][-1],\n",
    "            s=100,\n",
    "            color=colors[i % len(colors)],\n",
    "            zorder=5,\n",
    "            marker='s'\n",
    "        )\n",
    "        \n",
    "        plt.annotate(\n",
    "            f\"{history.history['val_accuracy'][-1]:.4f}\",\n",
    "            (len(history.history['val_accuracy']), history.history['val_accuracy'][-1]),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0,10),\n",
    "            ha='center',\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    plt.title('Model Accuracy Comparison', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim([0, 1.05])  # Set y-axis from 0 to slightly above 1\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(loc='lower right', fontsize=12)\n",
    "    \n",
    "    # Add timestamp and summary information\n",
    "    plt.figtext(\n",
    "        0.5, 0.01, \n",
    "        f'Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}',\n",
    "        ha='center', fontsize=10\n",
    "    )\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure if requested\n",
    "    if save_plot:\n",
    "        plt.savefig('model_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"Plot saved as 'model_accuracy_comparison.png'\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary table of final accuracies\n",
    "    final_metrics = {\n",
    "        'Model': model_names,\n",
    "        'Training Accuracy': [hist.history['accuracy'][-1] for hist in model_histories],\n",
    "        'Validation Accuracy': [hist.history['val_accuracy'][-1] for hist in model_histories],\n",
    "        'Epochs': [len(hist.history['accuracy']) for hist in model_histories]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(final_metrics)\n",
    "    print(\"\\n===== Model Accuracy Summary =====\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have three model history objects: history_effnet, history_mobnet, and history_custom\n",
    "\n",
    "# Example (replace with your actual history objects):\n",
    "plot_model_comparison(\n",
    "  [history, history_mobnet30, history_3],\n",
    "   ['EfficientNetB0', 'MobileNetV2', 'CustomModel']\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714ed85-aa7d-4de7-9ee6-ad2459be7690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
